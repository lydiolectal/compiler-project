#!/usr/bin/env python3

import argparse
from tokenizer import Tokenizer

if __name__ == '__main__':

    # parses arguments from command line.
    parser = argparse.ArgumentParser()
    parser.add_argument('f', type=str)
    vars = parser.parse_args()
    contents = []
    with open(vars.f, "r") as f:
        contents = f.read()

    if contents:
        tokenizer = Tokenizer(contents)
        tokens = tokenizer.tokenize()
        for token in tokens:
            print (str(token.data) + ":" + token.type)
